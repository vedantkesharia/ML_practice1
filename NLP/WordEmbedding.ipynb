{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embedding Techniques using Embedding Layer in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word embeddings are a type of word representation used in natural language processing (NLP) and machine learning tasks. They are dense vector representations of words or phrases, typically generated by training a neural network model on a large corpus of text data.\n",
    "\n",
    "In traditional NLP models, words are often represented as one-hot vectors, where each word is represented as a vector with a length equal to the size of the vocabulary, and all elements are zero except for the index corresponding to the word, which is set to one. However, one-hot representations have limitations, such as high dimensionality and inability to capture semantic relationships between words.\n",
    "\n",
    "Word embeddings address these limitations by representing words in a continuous vector space where semantically similar words are closer together. This allows machine learning algorithms to better understand the meaning and context of words.\n",
    "\n",
    "Popular techniques for generating word embeddings include:\n",
    "\n",
    "1. Word2Vec: Developed by researchers at Google, Word2Vec learns word embeddings by predicting the surrounding words given a target word or vice versa. It introduces two architectures: Continuous Bag of Words (CBOW) and Skip-gram.\n",
    "\n",
    "2. GloVe (Global Vectors for Word Representation): GloVe is another widely used word embedding technique that learns word vectors by factorizing the co-occurrence matrix of words.\n",
    "\n",
    "3. FastText: Developed by Facebook AI Research, FastText extends the idea of word embeddings to subword units (e.g., character n-grams). It can handle out-of-vocabulary words better and capture morphological information.\n",
    "\n",
    "4. ELMo (Embeddings from Language Models): ELMo generates word embeddings by using deep contextualized word representations. It captures word meanings based on the entire context in which the word appears.\n",
    "\n",
    "5. BERT (Bidirectional Encoder Representations from Transformers): BERT is a transformer-based model introduced by Google that produces contextualized word embeddings by considering both left and right context of a word.\n",
    "\n",
    "Word embeddings have revolutionized various NLP tasks, including sentiment analysis, text classification, machine translation, and named entity recognition, among others. They enable models to understand and process natural language more effectively by capturing semantic relationships between words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "##tensorflow >2.0\n",
    "from tensorflow.keras.preprocessing.text import one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "### sentences\n",
    "sent=[  'the glass of milk',\n",
    "     'the glass of juice',\n",
    "     'the cup of tea',\n",
    "    'I am a good boy',\n",
    "     'I am a good developer',\n",
    "     'understand the meaning of words',\n",
    "     'your videos are good',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the glass of milk',\n",
       " 'the glass of juice',\n",
       " 'the cup of tea',\n",
       " 'I am a good boy',\n",
       " 'I am a good developer',\n",
       " 'understand the meaning of words',\n",
       " 'your videos are good']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Vocabulary size\n",
    "voc_size=10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One Hot Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9139, 4022, 2881, 543], [9139, 4022, 2881, 4313], [9139, 9584, 2881, 1269], [5860, 5644, 8681, 1794, 250], [5860, 5644, 8681, 1794, 6833], [8573, 9139, 9874, 2881, 7108], [6163, 12, 3056, 1794]]\n"
     ]
    }
   ],
   "source": [
    "onehot_repr=[one_hot(words,voc_size)for words in sent] \n",
    "print(onehot_repr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embedding Represntation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0 9139 4022 2881  543]\n",
      " [   0    0    0    0 9139 4022 2881 4313]\n",
      " [   0    0    0    0 9139 9584 2881 1269]\n",
      " [   0    0    0 5860 5644 8681 1794  250]\n",
      " [   0    0    0 5860 5644 8681 1794 6833]\n",
      " [   0    0    0 8573 9139 9874 2881 7108]\n",
      " [   0    0    0    0 6163   12 3056 1794]]\n"
     ]
    }
   ],
   "source": [
    "sent_length=8\n",
    "embedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)\n",
    "print(embedded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim=10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "model = Sequential()\n",
    "# model.add(keras.layers.Embedding(voc_size,10,input_length=sent_length))\n",
    "model.add(keras.layers.Embedding(voc_size,10))\n",
    "model.compile('adam', 'mse')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_21\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_21\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_17 (\u001b[38;5;33mEmbedding\u001b[0m)        │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step\n",
      "[[[ 0.0262043  -0.01611923 -0.03827123  0.00063157 -0.02941749\n",
      "    0.04156742 -0.00797303 -0.04727795  0.02560146 -0.00595176]\n",
      "  [ 0.0262043  -0.01611923 -0.03827123  0.00063157 -0.02941749\n",
      "    0.04156742 -0.00797303 -0.04727795  0.02560146 -0.00595176]\n",
      "  [ 0.0262043  -0.01611923 -0.03827123  0.00063157 -0.02941749\n",
      "    0.04156742 -0.00797303 -0.04727795  0.02560146 -0.00595176]\n",
      "  [ 0.0262043  -0.01611923 -0.03827123  0.00063157 -0.02941749\n",
      "    0.04156742 -0.00797303 -0.04727795  0.02560146 -0.00595176]\n",
      "  [ 0.01091008  0.03084356 -0.01183671 -0.00431285  0.04714154\n",
      "    0.02576306  0.04124742  0.03667709 -0.02098651  0.01734051]\n",
      "  [-0.03053644  0.02257584 -0.03297468 -0.04387569 -0.04957369\n",
      "   -0.03963451  0.01510328 -0.04239064  0.0170014   0.04834378]\n",
      "  [ 0.02608517  0.02727618  0.04560426  0.02588158 -0.00081056\n",
      "    0.0315796   0.04283795 -0.04362474 -0.02920738 -0.0242644 ]\n",
      "  [-0.03730259 -0.03630115  0.0019968  -0.02655239 -0.03386085\n",
      "   -0.03092271 -0.0103241   0.03315813 -0.0012949   0.00582018]]\n",
      "\n",
      " [[ 0.0262043  -0.01611923 -0.03827123  0.00063157 -0.02941749\n",
      "    0.04156742 -0.00797303 -0.04727795  0.02560146 -0.00595176]\n",
      "  [ 0.0262043  -0.01611923 -0.03827123  0.00063157 -0.02941749\n",
      "    0.04156742 -0.00797303 -0.04727795  0.02560146 -0.00595176]\n",
      "  [ 0.0262043  -0.01611923 -0.03827123  0.00063157 -0.02941749\n",
      "    0.04156742 -0.00797303 -0.04727795  0.02560146 -0.00595176]\n",
      "  [ 0.0262043  -0.01611923 -0.03827123  0.00063157 -0.02941749\n",
      "    0.04156742 -0.00797303 -0.04727795  0.02560146 -0.00595176]\n",
      "  [ 0.01091008  0.03084356 -0.01183671 -0.00431285  0.04714154\n",
      "    0.02576306  0.04124742  0.03667709 -0.02098651  0.01734051]\n",
      "  [-0.03053644  0.02257584 -0.03297468 -0.04387569 -0.04957369\n",
      "   -0.03963451  0.01510328 -0.04239064  0.0170014   0.04834378]\n",
      "  [ 0.02608517  0.02727618  0.04560426  0.02588158 -0.00081056\n",
      "    0.0315796   0.04283795 -0.04362474 -0.02920738 -0.0242644 ]\n",
      "  [-0.02769891  0.04984322 -0.0114449  -0.03928328 -0.02849679\n",
      "   -0.01805627  0.04941047 -0.02433742 -0.03103496  0.0497885 ]]\n",
      "\n",
      " [[ 0.0262043  -0.01611923 -0.03827123  0.00063157 -0.02941749\n",
      "    0.04156742 -0.00797303 -0.04727795  0.02560146 -0.00595176]\n",
      "  [ 0.0262043  -0.01611923 -0.03827123  0.00063157 -0.02941749\n",
      "    0.04156742 -0.00797303 -0.04727795  0.02560146 -0.00595176]\n",
      "  [ 0.0262043  -0.01611923 -0.03827123  0.00063157 -0.02941749\n",
      "    0.04156742 -0.00797303 -0.04727795  0.02560146 -0.00595176]\n",
      "  [ 0.0262043  -0.01611923 -0.03827123  0.00063157 -0.02941749\n",
      "    0.04156742 -0.00797303 -0.04727795  0.02560146 -0.00595176]\n",
      "  [ 0.01091008  0.03084356 -0.01183671 -0.00431285  0.04714154\n",
      "    0.02576306  0.04124742  0.03667709 -0.02098651  0.01734051]\n",
      "  [ 0.02918417  0.04061407  0.04439268 -0.03689458 -0.00680236\n",
      "   -0.03982119  0.03986839  0.02660746  0.02925695 -0.01453302]\n",
      "  [ 0.02608517  0.02727618  0.04560426  0.02588158 -0.00081056\n",
      "    0.0315796   0.04283795 -0.04362474 -0.02920738 -0.0242644 ]\n",
      "  [ 0.00243236 -0.03575417  0.00277076 -0.04821141  0.03052957\n",
      "   -0.01048181 -0.01815521  0.04160025  0.04990896  0.01138034]]\n",
      "\n",
      " [[ 0.0262043  -0.01611923 -0.03827123  0.00063157 -0.02941749\n",
      "    0.04156742 -0.00797303 -0.04727795  0.02560146 -0.00595176]\n",
      "  [ 0.0262043  -0.01611923 -0.03827123  0.00063157 -0.02941749\n",
      "    0.04156742 -0.00797303 -0.04727795  0.02560146 -0.00595176]\n",
      "  [ 0.0262043  -0.01611923 -0.03827123  0.00063157 -0.02941749\n",
      "    0.04156742 -0.00797303 -0.04727795  0.02560146 -0.00595176]\n",
      "  [ 0.0405769  -0.00215421 -0.01084573  0.03112224 -0.030781\n",
      "   -0.00554436  0.00580393  0.0222324  -0.01984043  0.03633126]\n",
      "  [-0.01627151  0.04379287 -0.02195926  0.03281293 -0.00574964\n",
      "    0.0272732   0.01237258 -0.00300639  0.02893503  0.01864446]\n",
      "  [-0.03141411  0.02799726  0.00109654 -0.02754053 -0.04291783\n",
      "   -0.00851833  0.00642519  0.04236079 -0.04892284  0.04276686]\n",
      "  [-0.0072725  -0.01454774  0.00958339 -0.02558522 -0.04578751\n",
      "    0.01513085  0.04378483 -0.03792329 -0.02447109 -0.01684741]\n",
      "  [-0.00403454  0.03635199  0.0085947  -0.00500667  0.03829968\n",
      "    0.01647344  0.02369418 -0.01863987 -0.04174988 -0.01613925]]\n",
      "\n",
      " [[ 0.0262043  -0.01611923 -0.03827123  0.00063157 -0.02941749\n",
      "    0.04156742 -0.00797303 -0.04727795  0.02560146 -0.00595176]\n",
      "  [ 0.0262043  -0.01611923 -0.03827123  0.00063157 -0.02941749\n",
      "    0.04156742 -0.00797303 -0.04727795  0.02560146 -0.00595176]\n",
      "  [ 0.0262043  -0.01611923 -0.03827123  0.00063157 -0.02941749\n",
      "    0.04156742 -0.00797303 -0.04727795  0.02560146 -0.00595176]\n",
      "  [ 0.0405769  -0.00215421 -0.01084573  0.03112224 -0.030781\n",
      "   -0.00554436  0.00580393  0.0222324  -0.01984043  0.03633126]\n",
      "  [-0.01627151  0.04379287 -0.02195926  0.03281293 -0.00574964\n",
      "    0.0272732   0.01237258 -0.00300639  0.02893503  0.01864446]\n",
      "  [-0.03141411  0.02799726  0.00109654 -0.02754053 -0.04291783\n",
      "   -0.00851833  0.00642519  0.04236079 -0.04892284  0.04276686]\n",
      "  [-0.0072725  -0.01454774  0.00958339 -0.02558522 -0.04578751\n",
      "    0.01513085  0.04378483 -0.03792329 -0.02447109 -0.01684741]\n",
      "  [-0.03981817  0.02515585  0.0025838   0.00650547  0.03755968\n",
      "    0.04829898  0.03925078 -0.02256354  0.01321897  0.01763498]]\n",
      "\n",
      " [[ 0.0262043  -0.01611923 -0.03827123  0.00063157 -0.02941749\n",
      "    0.04156742 -0.00797303 -0.04727795  0.02560146 -0.00595176]\n",
      "  [ 0.0262043  -0.01611923 -0.03827123  0.00063157 -0.02941749\n",
      "    0.04156742 -0.00797303 -0.04727795  0.02560146 -0.00595176]\n",
      "  [ 0.0262043  -0.01611923 -0.03827123  0.00063157 -0.02941749\n",
      "    0.04156742 -0.00797303 -0.04727795  0.02560146 -0.00595176]\n",
      "  [-0.02604007 -0.02065411  0.02202176 -0.03469105 -0.01078136\n",
      "    0.04076162 -0.01975386 -0.01213302 -0.04645818 -0.01060668]\n",
      "  [ 0.01091008  0.03084356 -0.01183671 -0.00431285  0.04714154\n",
      "    0.02576306  0.04124742  0.03667709 -0.02098651  0.01734051]\n",
      "  [-0.00850964 -0.02016794 -0.03378196 -0.00167185 -0.00160527\n",
      "   -0.02440767  0.01071017 -0.03573873  0.03855156 -0.02847828]\n",
      "  [ 0.02608517  0.02727618  0.04560426  0.02588158 -0.00081056\n",
      "    0.0315796   0.04283795 -0.04362474 -0.02920738 -0.0242644 ]\n",
      "  [-0.01355007  0.04354305  0.02644953 -0.02149072 -0.00195509\n",
      "   -0.00932636 -0.00812678 -0.00490768 -0.03073874 -0.00622108]]\n",
      "\n",
      " [[ 0.0262043  -0.01611923 -0.03827123  0.00063157 -0.02941749\n",
      "    0.04156742 -0.00797303 -0.04727795  0.02560146 -0.00595176]\n",
      "  [ 0.0262043  -0.01611923 -0.03827123  0.00063157 -0.02941749\n",
      "    0.04156742 -0.00797303 -0.04727795  0.02560146 -0.00595176]\n",
      "  [ 0.0262043  -0.01611923 -0.03827123  0.00063157 -0.02941749\n",
      "    0.04156742 -0.00797303 -0.04727795  0.02560146 -0.00595176]\n",
      "  [ 0.0262043  -0.01611923 -0.03827123  0.00063157 -0.02941749\n",
      "    0.04156742 -0.00797303 -0.04727795  0.02560146 -0.00595176]\n",
      "  [-0.02754021  0.02225356  0.00890402 -0.0175061  -0.01049592\n",
      "    0.04483728 -0.00866742 -0.03361402  0.00698147 -0.04270866]\n",
      "  [ 0.00179208 -0.02829819  0.00897004 -0.00656457  0.01672566\n",
      "   -0.04599723 -0.00894421 -0.0251649  -0.04868963 -0.04811427]\n",
      "  [-0.02068551  0.03670858 -0.04108894  0.00932757  0.04874711\n",
      "   -0.01714713  0.00930209  0.00976211 -0.03620648 -0.00410474]\n",
      "  [-0.0072725  -0.01454774  0.00958339 -0.02558522 -0.04578751\n",
      "    0.01513085  0.04378483 -0.03792329 -0.02447109 -0.01684741]]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(embedded_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0, 9139, 4022, 2881,  543])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "[[ 0.0262043  -0.01611923 -0.03827123  0.00063157 -0.02941749  0.04156742\n",
      "  -0.00797303 -0.04727795  0.02560146 -0.00595176]\n",
      " [ 0.0262043  -0.01611923 -0.03827123  0.00063157 -0.02941749  0.04156742\n",
      "  -0.00797303 -0.04727795  0.02560146 -0.00595176]\n",
      " [ 0.0262043  -0.01611923 -0.03827123  0.00063157 -0.02941749  0.04156742\n",
      "  -0.00797303 -0.04727795  0.02560146 -0.00595176]\n",
      " [ 0.0262043  -0.01611923 -0.03827123  0.00063157 -0.02941749  0.04156742\n",
      "  -0.00797303 -0.04727795  0.02560146 -0.00595176]\n",
      " [ 0.01091008  0.03084356 -0.01183671 -0.00431285  0.04714154  0.02576306\n",
      "   0.04124742  0.03667709 -0.02098651  0.01734051]\n",
      " [-0.03053644  0.02257584 -0.03297468 -0.04387569 -0.04957369 -0.03963451\n",
      "   0.01510328 -0.04239064  0.0170014   0.04834378]\n",
      " [ 0.02608517  0.02727618  0.04560426  0.02588158 -0.00081056  0.0315796\n",
      "   0.04283795 -0.04362474 -0.02920738 -0.0242644 ]\n",
      " [-0.03730259 -0.03630115  0.0019968  -0.02655239 -0.03386085 -0.03092271\n",
      "  -0.0103241   0.03315813 -0.0012949   0.00582018]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(embedded_docs)[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
